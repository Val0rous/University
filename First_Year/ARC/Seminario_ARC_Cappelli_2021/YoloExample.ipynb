{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import va\n",
    "from ipywidgets import interact\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection con YOLO v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('images/tbbt.jpg')\n",
    "va.show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'yolov3.'\n",
    "net = cv.dnn.readNet(path + 'weights', path + 'cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = img.shape[:2]\n",
    "size = max(height, width)\n",
    "bh, bw = (size - height) // 2, (size - width) // 2\n",
    "padded_img = cv.copyMakeBorder(img, bh, size-height-bh, bw, size-width-bw, cv.BORDER_CONSTANT, (0,0,0))\n",
    "va.show(padded_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = cv.dnn.blobFromImage(padded_img, 1.0 / 255, (416, 416), swapRB = True)\n",
    "blob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va.show(*blob[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setInput(blob)\n",
    "output_names = net.getUnconnectedOutLayersNames()\n",
    "print(output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net.forward(output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classes = open(path + 'txt').read().split('\\n')\n",
    "Colors = cv.applyColorMap((np.arange(len(Classes)) * 43 % 256).astype(np.uint8)[...,np.newaxis], cv.COLORMAP_HSV).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(image, conf_threshold):    \n",
    "    height, width = image.shape[:2]\n",
    "    size = max(height, width)\n",
    "    bh, bw = (size - height) // 2, (size - width) // 2\n",
    "    padded_img = cv.copyMakeBorder(image, bh, size-height-bh, bw, size-width-bw, cv.BORDER_CONSTANT, (0,0,0))\n",
    "    net.setInput(cv.dnn.blobFromImage(padded_img, 1.0 / 255, (416, 416), swapRB = True))\n",
    "\n",
    "    detected_objects, confidences, class_indices = [], [], []\n",
    "    for out in net.forward(net.getUnconnectedOutLayersNames()):\n",
    "        for tx, ty, tw, th, p0, *scores in out:            \n",
    "            if (confidence := float(scores[ (class_index := np.argmax(scores)) ])) > conf_threshold:\n",
    "                x, y = int((tx - tw / 2) * size - bw), int((ty - th / 2) * size - bh)\n",
    "                w, h = int(tw * size), int(th * size)\n",
    "                detected_objects.append( (x, y, w, h) )\n",
    "                confidences.append(confidence)\n",
    "                class_indices.append(class_index)\n",
    "    return detected_objects, confidences, class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection(img, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_detected_object(img, class_index, confidence, box):\n",
    "    x, y, w, h = box\n",
    "    label = f'{Classes[class_index]} ({confidence*100:.2f}%)'\n",
    "    color, font = Colors[class_index].tolist(), cv.FONT_HERSHEY_PLAIN  \n",
    "    (sx,sy), baseline = cv.getTextSize(label, font, 1, 1)\n",
    "    cv.rectangle(img, (x,y), (x+w,y+h), color, 2)    \n",
    "    cv.rectangle(img, (x,y), (x+max(w,sx), y+sy+5), color, -1)\n",
    "    cv.putText(img, label, (x,y+baseline+6), font, 1, (255,255,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = img.copy()\n",
    "draw_detected_object(tmp, 42, 0.42, (42,42,199,99))\n",
    "va.show(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_detected_objects(image, detected_objects, confidences, class_indices, nms_threshold):         \n",
    "    boxes = cv.dnn.NMSBoxes(detected_objects, confidences, 0, nms_threshold)\n",
    "    if boxes is not None and type(boxes) is not tuple:\n",
    "        boxes = boxes.ravel()\n",
    "    for i in boxes:\n",
    "        draw_detected_object(image, class_indices[i], confidences[i], detected_objects[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = detection(img, 0.9)\n",
    "tmp = img.copy()\n",
    "draw_detected_objects(tmp, *res, 0.4)\n",
    "va.show(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colleghiamo una webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connessione e configurazione webcam\n",
    "def camera_open():\n",
    "    cam = cv.VideoCapture(0)\n",
    "    cam.set(cv.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cam.set(cv.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    for _ in range(10):\n",
    "        cam.read()\n",
    "    return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing video eseguendo una funzione su ciascun frame: \n",
    "# l'esecuzione termina quando viene interrotto il kernel\n",
    "def video_processing(processing_func):\n",
    "    cam = camera_open()\n",
    "    display_id = va.get_new_display_id()\n",
    "    while True:\n",
    "        try:   \n",
    "            frame = cam.read()[1]\n",
    "            img = processing_func(frame)\n",
    "            va.show((img), display_id=display_id)\n",
    "        except KeyboardInterrupt:\n",
    "            cam.release()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(frame):\n",
    "    img = frame.copy()\n",
    "    draw_detected_objects(img, *detection(frame, 0.4), 0.6)    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_processing(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
